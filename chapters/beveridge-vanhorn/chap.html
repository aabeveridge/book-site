<p><strong>Mining Hope: Preserving and Visualizing Network Data</strong></p>
<p><strong>Aaron Beveridge and Nicholas Van Horn</strong></p>
<p><strong>Introduction</strong></p>
<p><strong>Data visualization—the act of collecting data, processing it, and making sense of it visually through statistical methods—is a growing area of interest for rhetoric and writing studies more generally (Mueller, Beveridge, quantitative rhetoric article), and for digital visual studies in particular (Gries, Gallagher/Devoss). As pervasive and ubiquitous digital objects, data visualizations are embedded in everything from websites and news blogs to mobile applications and virtual dashboards. A data visualization can be as simple as an embedded image that compares categorical data—like a pie chart or a bar graph—or data visuals can be generated in a dynamic digital interface, allowing people to interact with the data and select how they are compared, the type of graph or chart that will be used, and the time/date range that will frame the visualized comparison. From a design standpoint, a data visualization can be as basic as creating a graph or chart in Microsoft Excel or Google Sheets, using hand coded data from an observational study, or a data visualization can be as complex as calculating network-wide trends for an entire social network—in real time—to display visual lists of the hottest topics and #hashtags for various regions/locations/networks. Given the vast diversity of types and possibilities for designing data visualizations, one thing remains true for all of them: data visualizations are only as effective as their underlying data.<br />
This point may seem obvious or trite, but as this chapter will show, it is a mistake to assume the pervasive ubiquity of data visuals equates to the same level of ubiquitous access for researchers who want to study the underlying data and processing methods that power those visuals. Data has become “the new oil”—a popular metaphor demonstrating the powerful capabilities of data driven methods, but the oil metaphor also forces us to consider the harmful pollutants these methods continue to introduce to digital networks. Because of their shifting status as a resource of value—both economically and culturally—data visualizations maintain an inverse relationship with the underlying data that informs their making. In other words, as data visualizations have become more wide-spread and easier to produce, their underlying data have become financially lucrative and therefore less accessible. For example, Twitter’s data reselling and licensing (allowing other companies to access and analyze their network data) is now a primary source of revenue—representing up to $117 million in annual revenue for the company, and over 12% of its total annual revenue. But, if you consider the fact that Twitter’s data is what powers its programs and algorithms—the systematic delivery of advertisements to users feeds—then Twitter’s data actually accounts for the vast majority of its $908 million of annual revenue (Dignan).</strong></p>
<p><strong>The lack of accessibility for digital data presents many challenges for digital visual studies.</strong> Without adequate access to the underlying data, academic researchers have a difficult time studying the harmful downside of data-driven methods for digital networks: bots, click farms, echo chambers, information cascades, the unintended consequences of algorithmic filtering, the surveillance economy, privacy infringements, and fake news/misinformation campaigns. To be clear, we do not see these challenges as disqualifying data-driven methods for digital visual research. In fact, quite the opposite. Like rhetoric, the methods emerging from data science can function as both poison and remedy, depending on the methodology that frames the use of data-driven tools and techniques. Just as data-driven methods can be used to fuel targeted marketing and large-scale digital manipulation, these same methods also provide powerful tools for observing, understanding, and countering digital pollutants.</p>
<p>For example, in 2015 Eunsong Kim published “The Politics of Trending,” showing how</p>
<p>Twitter’s trend monitoring algorithms were ignoring—and potentially suppressing—trends</p>
<p>associated with #blacklivesmatter. To conduct this study, Kim used a data analytics tool called Topsy—a web application providing free trend analytics for networks like Twitter. Kim used Topsy’s analytics to investigate why trends like #Ferguson were not appearing on Twitter’s trending lists for the United States, because Topsy’s analytics clearly show that #Ferguson produced far more tweets than other trends on Twitter’s list. As Kim explains, her findings do not prove that Twitter was intentionally suppressing social movement trends, as her results likely indicate an unintended consequence of Twitter’s algorithmic design for identifying trends in their network. However, the more problematic legacy of Kim’s research is this: it is no longer possible to replicate Kim’s analysis. The opening section of this chapter, “Mergers and Acquisitions in Big Data,” explains why data preservation and access remain key issues for expanding the use of data-driven methods in digital visual research. If we are to make use of data-driven tools to understand and eliminate many of the digital pollutants, but also to study the circulation and rhetorical consequentiality of digital visual artifacts <em>at scale</em>, then we must continue to address the problem of data accessibility for digital networks.</p>
<p><strong>The final two sections of this chapter (“Data Archiving and Preservation” and “Data Visualization”) contribute to the application of data-driven methods in digital visual studies—and to Obamicon research—by showing readers how we archived, preserved, and visualized 14,588 Tweets (referred to as “Obama Hope Tweets” throughout the article) discussing Shepard Fairey’s Obama Hope image. The “Data Preservation” section shows researchers how to preserve and access this and other Tweet archives for their own digital visual projects, and these activities ensure that researchers will be able replicate the analytics and visuals produced by other scholars—for peer review and for collaborators and future scholars who wish to build on that work. This enables researchers to test and explore these same data in new ways, but this work also contributes to important intellectual movements, such as <a href="https://en.wikipedia.org/wiki/Open_data">open data</a> and <a href="https://dataforgood.ca/">data for good</a>.</strong></p>
<p><strong>The “Data Visualization” section of this chapter visualizes the data associated with the Obama Hope Tweets to provide a macroscopic history of Fairey’s “Obama Hope” image—from 2008 to 2018. While it is important for our readers to remember that this is only a history according to Twitter, this visual history provides a macroscopic view of the public conversation surrounding Fairey’s iconic image. XXX conclude and transition XXX</strong></p>
<p><strong>Mergers and Acquisitions in Big Data</strong></p>
<p>While the cultural and economic value of data from digital technologies continues to rise at a rapid pace, a consequence of this immense value is restricted access. Digital data sources include social networks, search engines, content providers, news aggregators, web services, mobile applications, and the Internet of Things (IoT). Research access to many digital sources remains limited because digital technologies are often proprietary and the most valuable data types are protected for the sake of targeted advertising or sold for marketing and product development research. This poses significant problems for scholars who want to study the cultural impact of digital activism, the network effects of viral media, the history and circulation of digital artifacts, and the effects of emerging digital technologies. As Aral Balkan argues, proprietary approaches to digital data are rooted in a “Silicon Valley” business model wherein user data from web/mobile applications and other digital technologies (such as IoT) provide a significant and growing source of revenue for both nascent and established digital technologies. While this model remains a key motivator behind digital privacy infringements, corporate surveillance, and the manipulative forms of data mining exemplified in Facebook’s Cambridge Analytica scandal, this section will focus on another troubling business practice that directly affects humanities scholars access to digital data: corporate acquisitions and mergers in the big data industry.</p>
<p>As we mentioned in the introduction, Eunsong Kim’s “The Politics of Trending” was published in 2015 to demonstrate how Twitter’s trend monitoring algorithms were ignoring—and potentially suppressing—trends associated with #blacklivesmatter. Kim used Topsy—a trend analytics tool for various social networks—to conduct her research. While Kim relied on Topsy’s free trend analytics to investigate why trends like #Ferguson were not appearing on Twitter’s trending lists for the United States, Topsy used these same free services to up-sell potential clients on their more comprehensive business data services. Certainly, there’s nothing wrong with a business providing a valuable service, and charging other businesses a reasonable fee for that service—assuming that their business practices are ethical and legal. But when most of the accessible toolsets for studying social networks are designed for marketing and product development research—aside from toolsets made available in programming languages such as R and Python, which require high-level programming skills to use—this creates a needless bottleneck constraining the types of research questions we can explore (Beveridge). However, while marketing tools like Topsy have many limitations when used for academic research, they still support research like Kim’s “The Politics of Trending.”</p>
<p>There are two key reasons why it is no longer possible to replicate the results of Kim’s research. First, Apple purchased Topsy in 2013 for $200 million, and then proceeded to shut Topsy down entirely in December of 2015. Therefore, it is literally impossible to use Topsy as Kim did for her article. The former director of business development at Topsy, Aaron Hayes-Roth—who was unhappy with Apple’s decision to shut Topsy down—wrote an editorial trying to answer a simple question: why would Apple pay $200 million for a business like Topsy, only to close its doors two years later? According to Hayes-Roth, Apple wanted to use Topsy’s data mining technology to compete with Google’s search/advertising services and thus Apple closed Topsy to use its data and computational technologies for Apple’s own search services (cite). Thus, the erasure of Kim’s methods were a consequence of Apple trying to compete with Google (cite), but this example is not an isolated incident—this is a direct consequence of a venture capital business model that drives the development of most digital technologies. The sarcastic profile description on Topsy’s still-available Twitter page summarizes the problem well: “Every Tweet ever published. <em>Previously</em> at your fingertips” (emphasis added).</p>
<p>[ insert video clip of Aral Balkan here—talking about the venture capital model and the problem with “free” cloud tools/software/analytics, time stamp 35:02, URL: https://www.youtube.com/embed/jh8supIUj6c?start=2102]</p>
<p>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/jh8supIUj6c?start=2102" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;</p>
<p>Humanities scholars must question the use and sustainability of “free” cloud</p>
<p>tools for data-driven humanities research. Certainly, there are some cloud tools that provide an</p>
<p>immense service to data-driven humanities research, such as Voyant (which is available as both a cloud tool and as standalone open source software). Voyant’s free cloud application provides natural language analytics that are easy to use, and we regularly use this tool in our classrooms and workshops to teach text mining and to introduce data-driven methods. Many other cloud tools like Trendsmap and SumAll may <em>appear</em> useful for humanities research, but these tools were not built for peer-reviewed academic research—they were built for business analytics and influencer marketing. This is an important difference that needs more critical reflection. For example, when we started to test the application of data-driven methods for circulation research in late 2013—in preparation for our <em>digital humanities quarterly</em> article, “Attention Ecology: Trend Circulation and the Virality Threashold”—we used Trendsmap to explore trending topics and their movements from location to location. When it became apparent that Trendsmap and other similar tools would not export data without us having to pay fees we could not afford, Nicholas Van Horn decided to write code himself that would provide us with the raw data we needed from Twitter’s application programming interface (API). In the 5 years since we started MassMine, Trendsmap continues their limited “free” business model, intended to up-sell users for their fee-based services.</p>
<p>Again, we see nothing wrong with Trendsmap charging fees for useful services, but we have to seriously question the sustainability of these types of tools for academic research. For example, SumAll’s justification for providing free access to data analytics is as follows: “Since we’re still working on building great products for small businesses, SumAll is free. Think of this as our soft launch—no credit cards and no subscriptions required.” In other words, SumAll is explicitly telling users their free access will not be sustained. Humanities scholars should look to the future and ask: how long until SumAll is acquired, fundamentally changed, or no longer available? Similarly, we might ask ourselves: if humanities scholars produce research using data from SumAll, and then SumAll is acquired and closed like Topsy, how can future scholars trust the findings of research that relies on results that cannot be replicated, tested, or otherwise evaluated? Additionally, cloud applications like SumAll do not provide users with access to the underlying data and methods used to produce their analytics, and therefore users of tools like SumAll have to simply trust the data visuals (analytics) presented to them. This may not be a problem for business analytics, but it is impossible to peer review data visuals that are based on proprietary, black boxed methods.</p>
<p>In March of 2018, Facebook’s primary third-party data provider Datasift was acquired by</p>
<p>Meltwater, a business analytics firm specializing in data mining technologies. Similarly, Twitter’s primary data partner GNIP, which Twitter purchased in 2014, has now been fully merged with Twitter’s new “Enterprise” developer services. While Facebook continues to systematically reduce the free public access to their data, Twitter has showed renewed efforts to work closely with developers in addressing the many democratic challenges facing digital networks. This is a good sign for digital humanities researchers, as Twitter and GNIP have provided many useful datasets for answering challenging questions about the changing nature of social movements in digital environments and the effects of networking technologies on democratic discourse. These changes at Twitter are promising, as are other recent trends, like Apple’s efforts to be an industry leader in protecting user privacy rights. However, the public availability of proprietary digital data (like Twitter data) for academic research has not improved since 2015, and relying too heavily on Twitter data as we develop sustainable data-driven methodologies for the humanities poses a significant risk. Twitter is a publicly traded corporation whose main goal, by that very definition, is providing its shareholders with profitable returns on their investments through the monetization of public and private user data for targeted marketing and the selling of advertisements. In this regard, Twitter and Facebook are the same.</p>
<p>This brings me to the second reason why it is no longer possible to replicate the results of Kim’s research: Twitter no longer allows it. Twitter’s newest terms of service—which were likely revised in response to tools like Topsy—reads as shown in Figure 1:</p>
<p><img src="media/image1.png" style="width:6.5in;height:2.01875in" /></p>
<p>Figure 1 is a screencapture of Twitter’s terms of service from July 2019 [hyperlink this to Waybackmachine of current page], and it shows how Twitter now explicitly blocks the use of their data for benchmarking or testing the effectiveness (“responsiveness”) of Twitter as a network. In other words, Twitter now blocks the use of their proprietary data—data that they received for free from users who post on their network—and if those same users want to aggregate that data to test the effectiveness of Twitter, that is explicitly prohibited. Twitter’s terms of service stops users from aggregating their data and testing whether or not Twitter—or Twitter’s advertisers—are overtly manipulating trends and user feeds. As we learned from Facebook’s Cambridge Analytica scandal, a lack of accountability for social networks is not only a threat to the open circulation of diverse ideas and content, but a very real threat to sovereign government elections and the democratic discourse on which those governments and elections are founded.</p>
<p>It is no stretch to say that open access to digital data—of all kinds—is among the most exigent contemporary issues facing digital visual studies, digital rhetoric, and the digital humanities. While we are encouraged by recent efforts to discuss the regulation of social networks among U.S. lawmakers, we fear that the current regulatory climate in Washington D.C. will not lead to the type of accountability that ought to be immediately enacted. The next section will XXX conclude and transition XXX</p>
<p><strong>Data Archiving and Preservation</strong></p>
<p>Among the most important projects in the areas of data accessibility and the</p>
<p>preservation of digital data is The Internet Archive (archive.org), which works to</p>
<p>preserve access to a broad diversity of digital sources with its WayBackMachine and other</p>
<p>similar tools. The WayBackMachine provides a sustainable way to hyperlink webpages for articles—ensuring that webtexts will not suffer <a href="https://en.wikipedia.org/wiki/Link_rot">link rot</a>. For example, any of the links in this article that point to web pages that could be changed or deleted utilize the WayBackMachine’s saved instance of the webpage, rather than directing readers to the source material directly. We also rely on this same preservation technique for the <a href="http://aaronbeveridge.com/book-site/chapters/archives/introduction.html">archive of Obamicons</a>, curated for this collection.</p>
<p>A project similar to The Internet Archive, called <a href="https://www.docnow.io/">DocNow</a>, “support[s] the ethical collection, use, and preservation of social network data.” DocNow’s preservation of Tweet ID datasets represents a significant contribution to the sustainability of data-driven methods in the digital humanities, and this section shows digital visual scholars how archive and preserve social network datasets for research. The <a href="https://www.docnow.io/catalog/">Obama Hope Tweets</a> dataset that we collected for this chapter is now available through DocNow’s catalog of Twitter datasets. As DocNow continues to grow their archive of Twitter data, they now have a wide diversity of social movement and political datasets. For example, they archived 39,622,026 tweet IDs related to public <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/5QCCUU">discussions of climate change</a>, from September of 2017 until May of 2019 (tags: climate change, environment, politics). They also have a <a href="https://archive.org/details/blacklivesmatter-tweets-2016.txt">#blacklivesmatter dataset</a>, consisting of 17,292,130 tweets from January of 2016 until March of 2017 (tags: blacklivesmatter, activism).</p>
<p>The method we forward in this section can be used for any set of Tweets collected by any means that retain the original Tweet ID for each message, including those datasets generated by MassMine [XXX citation]. We have added <em>rehydration</em> technology to MassMine, which provides the necessary tools for researchers to download the full “rehydrated” datasets from Twitter. DocNow only archives the Tweet <em>IDs—</em>which are tweet identification numbers, unique for every tweet published on Twitter, and used by Twitter’s API to access and download the data associated with the original tweets. This “rehydration” terminology and method is forwarded by Twitter’s own terms of service for their developers (users of their API), and it does come with limitations. For example, Twitter does not allow the sharing of complete tweet datasets publicly in the cloud, but it does permit researchers to curate and disseminate collections of unique tweet identification numbers. These unique codes allow researchers to retrieve any specific tweet's full text and associated metadata. While <em>rehydration</em> is a roundabout process, designed in principle to provide individual Twitter users with some measure of control over their own data, the downside is that these curated histories of Tweets are not exactly accurate or stable. Because Twitter forces rehydration through Twitter's own server, individual users can (and often do) revise their Twitter histories be deleting previous posts. Certainly, we believe that individual users should have control over their data—including the ability to delete past posts—but this represents an obvious problem for the rehydration methodology as designed by Twitter. Instead of resurrecting a tweet as it originally was written at the time of archiving, rehydrating a tweet will return its current form regardless of its original age and content. Rehydrating a deleted tweet will fail to retrieve the original full text. This trade-off with user agency is worth it, in our opinion, but it means that fully recoverable Twitter datasets are not guaranteed.</p>
<p>For this project, a dataset of 14,588 tweets were collected spanning the years 2008 to 2016, inclusive. The keywords guiding the data collection were restricted to "fairey AND hope" to gather posts that were specifically responding to, commenting on, or sharing content associated with Sheppard Fairey's "Obama Hope" image. We tested a range of queries like “Obama AND hope” using Twitter’s advanced search functionality, but many of the queries returned substantial noise. For example, we would see lots of tweets like, “I sure hope Obama can fix healthcare,” and other prevalent uses of the words “Obama AND hope” that did not at all address Fairey’s poster or its many remixes. Other more complex queries had similar issues, and while they returned substantially more data, they were far too sparse regarding tweet’s about Fairey’s Obama Hope.</p>
<p>Preparing the data for sharing through the DocNow web archive involved first reducing the tweets to individual identifiers. Common practices for DocNow’s catalog reveal that tweet IDs are shared in plain text, a robust format that prevents <a href="https://en.wikipedia.org/wiki/Vendor_lock-in">software lock-in</a>. Individual records are arranged with one ID per line, separated by newlines only. In this format, the Obama Hope Tweets are self-contained in file of 242 kilobytes. Finally, the file was compressed using gzip—a free and open source compression software—reducing the final shareable size to 106 kilobytes.</p>
<p>Due to DocNow's integration with GitHub, archiving datasets is entirely possible within DocNow's own website repository. However, convention and good practices recommend a proper repository, such as the Internet Archive (https://www.archive.org), which includes proper categorization, search, and integration through metadata support. Creating a new collection on the Internet Archive requires a free account, which can be accomplished quickly following the links provided on their website. Once in possession of an account, adding a prepared dataset requires little time. First, click on the "Upload" link provided at the top right of any archive.org web page. When prompted, click on the "Upload Files" button (Figure 1).</p>
<p><strong>[Figure 1]</strong></p>
<p>From here, the Internet Archive provides an intuitive drag-and-drop interface (Figure 2) for selecting your tweet ID data file. Be sure to name the file appropriately on your local computer before beginning this step. Once uploaded, the interface provides a method to add custom metadata to the collection (see Figure 3 for a complete list). This final step also provides an opportunity to set an appropriate license. For this project a Creative Commons "Attribution-NoDerivatives 4.0 International" license was chosen. Take special note of the "Page URL" field in the metadata summary. This link is necessary when including your collection in the DocNow archive.</p>
<p><strong>[Figure 2]</strong></p>
<p><strong>[Figure 3]</strong></p>
<p>While the Internet Archive provides a reliable and centralized online library for sharing information of all kinds, we elected to further register our dataset with DocNow. Documenting the Now's stated goal of "chronicling historically significant events [on social media]" provides scholars with a centralized location to document events important to digital citizenry [XXX CITATION: https://www.docnow.io/ ]. We support such data documentation and transparency efforts through our own submission, and hope that others will help to enrich such databases with their own contributions. Thankfully, DocNow's aim to simplify the process for archivists delivers. Note that this process will require a free account at https://github.com/. To begin, visit https://www.docnow.io/ and navigate down the page to find the link for the "Tweet Catalog." Click on the "Add yours!" link found under the Tweet Catalog icon (see Figure 4) to visit <a href="https://github.com/DocNow/catalog">https://github.com/DocNow/catalog</a>.</p>
<p><strong>[Figure 4 here]</strong></p>
<p>A simple set of provided directions detail how to add your dataset to the repository. In short, the process involves adding the metadata of a collection, including the URL that points to your dataset on archive.org, to a plain text document on Github.com. The metadata document is in YAML (YAML Ain't Markup Language) format, an open standards set of rules for encoding information in plain text. Adding a collection is simple, even for those uninitiated with YAML formatting, as the editing itself can be done directly in the browser, and proper formatting can be easily accomplished by mimicking other entries found in the database file (Figure 5).</p>
<p><strong>[Figure 5 here]</strong></p>
<p>Once your edits are complete, so you can submit the revisions and make a pull request (a formal request on GitHub for the maintainers of DocNow to inspect and confirm your addition to the database). The process of initiating a pull request can be completed with a click of a clearly-identified button in your browser, requiring very little technical knowledge. A message through Github will confirm once your collection is officially added to the DocNow repository, after which time changes should be reflected in the Tweet Catalog archive at <a href="https://www.docnow.io/catalog/">https://www.docnow.io/catalog/</a>.</p>
<p>XXX conclude and transition XXX</p>
<p><strong>Data Visualization</strong></p>
<p><strong>Conclusion</strong></p>
